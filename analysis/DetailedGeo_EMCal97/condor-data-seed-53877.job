# All local jobs are part of the vanilla universe.
Universe       = vanilla

# We want email if the job completed successfully. This can
# be set to Always, Error, or Never.
Notification   = Never

PeriodicHold   = (NumJobStarts>=1 && JobStatus == 1)

# Jobs by default get 1.4Gb of RAM allocated, ask for more if needed
# but if a job needs more than 2Gb it will not be able to run on the
# older nodes
request_memory = 4GB

# If you need multiple cores you can ask for them, but the scheduling
# may take longer the "larger" a job you ask for
request_cpus=1

# This flag is used to order only one's own submitted jobs 
# The jobs with the highest numbers get considered for 
# scheduling first.
Priority=20

# Copy all of the user's current shell environment variables 
# at the time of job submission.
GetEnv=True

# The requirement line specifies which machines we want to
# run this job on.  Any arbitrary classad expression can
# be used.
Requirements=(CPU_Speed >= 1)

# Rank is an expression that states how to rank machines which 
# have already met the requirements expression.  Essentially, 
# rank expresses preference.  A higher numeric value equals better 
# rank.  Condor will give the job the machine with the highest rank.
Rank=CPU_Speed

# Used to give jobs a directory with respect to file input 
# and output.
Initialdir     = /sphenix/u/xyu3/workarea/PhotonConv/analysis/DetailedGeo_EMCal97

# The executable we want to run.
Executable     = $(Initialdir)/run_photonconv_seed.sh

Nevent         = 5000
RunNumber      = 53877
ClusterFileName= DST_TRKR_CLUSTER_run2pp_ana489_2024p020_v001-$INT(RunNumber,%08d)-$INT(TrkrSegment,%05d).root
ClusterFilePath= /sphenix/lustre01/sphnxpro/production/run2pp/physics/ana489_2024p020_v001/DST_TRKR_CLUSTER/run_00053800_00053900/dst/
SeedFileName   = DST_TRKR_SEED_run2pp_ana493_2024p021_v001-$INT(RunNumber,%08d)-$INT(TrkrSegment,%05d).root
SeedFilePath   = /sphenix/lustre01/sphnxpro/production/run2pp/physics/ana493_2024p021_v001/DST_TRKR_SEED/run_00053800_00053900/dst/
CaloFileName   = DST_CALO_run2pp_ana468_2024p012_v001-$INT(RunNumber,%08d)-$INT(CaloSegment,%05d).root
CaloFilePath   = /sphenix/lustre01/sphnxpro/production/run2pp/physics/ana468_2024p012_v001/DST_CALO/run_00053800_00053900/dst/
OutPrefix      = clusters_seeds
OutPath        = $(Initialdir)
Index          = 0
StepSize       = 0

# The argument to pass to the executable.
#tracking firt then calo, only one tracking file
Arguments      = "$(Nevent) $(ClusterFileName) $(ClusterFilePath) $(SeedFileName) $(SeedFilePath) $(CaloFileName) $(CaloFilePath) $(OutPrefix) $(OutPath) $(Index) $(StepSize)"

# The job's stdout is sent to this file.
Output         = $(Initialdir)/log/job-Data-$(RunNumber).$(TrkrSegment).$(Cluster).$(Process).out

# The job's stderr is sent to this file.
Error          = $(Initialdir)/log/job-Data-$(RunNumber).$(TrkrSegment).$(Cluster).$(Process).err

# The condor log file for this job, useful when debugging.
Log            = $(Initialdir)/log/job-Data-$(RunNumber).$(TrkrSegment).$(Cluster).$(Process).log

#should_transfer_files   = YES
#when_to_transfer_output = ON_EXIT_OR_EVICT
#transfer_output_files   = dummy.cc

on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

#Limiting the number of running jobs
#concurrency_limits=CONCURRENCY_LIMIT_DEFAULT:1000

# This should be the last command and tells condor to queue the
# job.  If a number is placed after the command (i.e. Queue 15)
# then the job will be submitted N times.  Use the $(Process)
# macro to make your input/output and log files unique.
Queue TrkrSegment CaloSegment from $(Initialdir)/filelist/dst_sync_trkr_seed_cluster_calo_run2pp-$INT(RunNumber,%08d).list
