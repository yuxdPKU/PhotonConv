# All local jobs are part of the vanilla universe.
Universe       = vanilla

# We want email if the job completed successfully. This can
# be set to Always, Error, or Never.
Notification   = Never

PeriodicHold   = (NumJobStarts>=1 && JobStatus == 1)

# Jobs by default get 1.4Gb of RAM allocated, ask for more if needed
# but if a job needs more than 2Gb it will not be able to run on the
# older nodes
request_memory = 10GB

# If you need multiple cores you can ask for them, but the scheduling
# may take longer the "larger" a job you ask for
request_cpus=1

# This flag is used to order only one's own submitted jobs 
# The jobs with the highest numbers get considered for 
# scheduling first.
Priority=20

# Copy all of the user's current shell environment variables 
# at the time of job submission.
GetEnv=True

# The requirement line specifies which machines we want to
# run this job on.  Any arbitrary classad expression can
# be used.
Requirements=(CPU_Speed >= 1)

# Rank is an expression that states how to rank machines which 
# have already met the requirements expression.  Essentially, 
# rank expresses preference.  A higher numeric value equals better 
# rank.  Condor will give the job the machine with the highest rank.
Rank=CPU_Speed

# Used to give jobs a directory with respect to file input 
# and output.
Initialdir     = /sphenix/u/xyu3/workarea/PhotonConv/ana441_trackdst_ana

# The executable we want to run.
Executable     = $(Initialdir)/run_data.sh

Nevent         = -1
RunNumber      = 51604
TracksList     = ./runList/dstlist/dst_trkr_tracks_run2pp-$INT(RunNumber,%08d).list
ClusterList    = ./runList/dstlist/dst_trkr_cluster_run2pp-$INT(RunNumber,%08d).list
CaloList       = ./runList/dstlist/dst_calo_run2pp-$INT(RunNumber,%08d).list
OutDir         = $(Initialdir)

# The argument to pass to the executable.
#tracking firt then calo, only one tracking file
Arguments      = "$(Nevent) $(TracksList) $(ClusterList) $(CaloList) $(OutDir)"

# The job's stdout is sent to this file.
Output         = $(Initialdir)/condorJob/log/job-Data-$(RunNumber).$(Cluster).$(Process).out

# The job's stderr is sent to this file.
Error          = $(Initialdir)/condorJob/log/job-Data-$(RunNumber).$(Cluster).$(Process).err

# The condor log file for this job, useful when debugging.
Log            = $(Initialdir)/condorJob/log/job-Data-$(RunNumber).$(Cluster).$(Process).log

#should_transfer_files   = YES
#when_to_transfer_output = ON_EXIT_OR_EVICT
#transfer_output_files   = dummy.cc

on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

#Limiting the number of running jobs
concurrency_limits=CONCURRENCY_LIMIT_DEFAULT:1000

# This should be the last command and tells condor to queue the
# job.  If a number is placed after the command (i.e. Queue 15)
# then the job will be submitted N times.  Use the $(Process)
# macro to make your input/output and log files unique.
Queue
#Queue JOBNUMBER
#Queue TpcList from $(Initialdir)/runList/dst_tpc_event_run2pp-$INT(RunNumber,%08d).list
